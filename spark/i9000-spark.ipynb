{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.5em;color:purple; font-style:bold\"><br/>\n",
    "I9000平台Spark使用基础\n",
    "</p>\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "I9000云平台鸟瞰（复习）\n",
    "</p>\n",
    "\n",
    "- 应用发布与管理平台\n",
    "- 分布式存储与计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "大数据存储与计算最常用的两个工具\n",
    "</p>\n",
    "\n",
    "- HDFS\n",
    "  - Hadoop分布式文件系统\n",
    "- Spark\n",
    "  - 分布式计算引擎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "HDFS – Hadoop分布式文件系统\n",
    "</p>\n",
    "\n",
    "- 文件系统\n",
    "  - 树形结构组织的目录和文件\n",
    "  - Linux命令行使用ls、cd等命令切换和查看\n",
    "  - Windows使用我的电脑查看\n",
    "  - 在编程语言例如Python中，通过调用函数访问\n",
    "- HDFS分布式文件系统，使用者角度\n",
    "  - 与普通文件系统类似\n",
    "  - 主要的区别是能够存放大文件，比如一个文件几百GB或几个T\n",
    "- HDFS作为数据存储层，属于I9000系统的组成部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "HDFS为什么能够存储大文件（架构概览）\n",
    "</p>\n",
    "\n",
    "<img src=\"i9000-spark-image/hdfs.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "在I9000中使用HDFS\n",
    "</p>\n",
    "\n",
    "- HDFS是I9000的数据层\n",
    "- 通过I9000的Web界面上传数据\n",
    "  - 存放在HDFS中\n",
    "- 使用这些文件\n",
    "  - 通过文件在HDFS上的URI来访问文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "练习 – 上传文件到HDFS\n",
    "</p>\n",
    "\n",
    "- 本地文件路径（XXX替换为云桌面用户名）\n",
    "\n",
    "> /home/XXX/i9000-training/spark/spark-readme.md\n",
    "\n",
    "- 请保存上传文件的URI，下面练习会用到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Spark – 分布式计算引擎\n",
    "</p>\n",
    "\n",
    "- 统一的平台\n",
    "  - 数据加载、SQL分析、机器学习、流式计算\n",
    "  - 一致性的编程接口\n",
    "  - 同时支持交互式分析和应用程序开发\n",
    "- Spark只是计算引擎，可以采用多种数据引擎\n",
    "  - HDFS\n",
    "  - Sql数据库\n",
    "  - NoSql数据库\n",
    "  - 消息队列，例如Apache Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Spark应用程序组成\n",
    "</p>\n",
    "\n",
    "<img src=\"i9000-spark-image/spark-overview.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Spark多语言支持\n",
    "</p>\n",
    "\n",
    "- Spark核心是Scala语言编写\n",
    "  - 运行在JVM上\n",
    "- Spark支持的用户语言\n",
    "  - Scala\n",
    "  - Java\n",
    "  - Python\n",
    "  - R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "使用Python时的进程关系\n",
    "</p>\n",
    "\n",
    "<img src=\"i9000-spark-image/python-process.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Spark应用编程接口（API）\n",
    "</p>\n",
    "\n",
    "- 低层无结构的RDD\n",
    "- 高层有结构的DataFrame\n",
    "- 高层DataFrame建筑在低层RDD之上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Spark编程入口\n",
    "</p>\n",
    "\n",
    "- 2.x版本\n",
    "  - SparkSession\n",
    "- 1.x版本\n",
    "  - SparkContext\n",
    "- 今天的例子使用1.x版本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "I9000中Spark交互式环境\n",
    "</p>\n",
    "\n",
    "- Python Spark Shell\n",
    "- Jupyter Notebook\n",
    "  - 讲稿正在用的环境"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "Python Spark Shell\n",
    "</p>\n",
    "\n",
    "- 使用Python语言的Spark交互环境\n",
    "- 在I9000中启动\n",
    "  - Jupyter terminal\n",
    "- 自动创建SparkContext对象\n",
    "  - pyspark中，绑定到sc变量上\n",
    "- SparkContext位于驱动进程（driver）中\n",
    "  - 是用户代码与Spark集群沟通的桥梁\n",
    "- 每个Spark应用程序对应一个SparkContext对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "低层编程接口 - RDD\n",
    "</p>\n",
    "\n",
    "- Resilient Distributed Dataset\n",
    "  - 弹性分布式数据集\n",
    "- 想象为一个大的列表，类似python的list\n",
    "  - 不同的是，元素存放在集群的多个节点中\n",
    "- RDD是不可变的\n",
    "  - 修改RDD，不会改变旧的，而是创建新的RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "RDD的创建\n",
    "</p>\n",
    "\n",
    "- 从现有序列创建\n",
    "  - SparkContext对象的parallelize()方法\n",
    "- 从外部存储系统创建，例如HDFS\n",
    "  - 例如文本文件：SparkContext对象的textFile()方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入python spark库\n",
    "import pyspark\n",
    "\n",
    "# 创建SparkContext对象\n",
    "sc = SparkContext()\n",
    "\n",
    "# 将本地列表分发到集群，创建RDD\n",
    "rdd_1 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "\n",
    "# 查看RDD的前三个元素\n",
    "print(rdd_1.take(3))\n",
    "\n",
    "# 收集集群中RDD的所有元素到本地\n",
    "print(rdd_1.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "RDD的两类操作\n",
    "</p>\n",
    "\n",
    "- 转换操作（transformation）\n",
    "  - 输入一个RDD，输出一个新的RDD\n",
    "- action操作\n",
    "  - 输入一个RDD，输出一个值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "RDD的转换操作示例 - map\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rdd = rdd_1.map(lambda x: x * 2)\n",
    "new_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "RDD的action操作示例 - reduce\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_1.reduce(lambda result, x: result + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "练习中用到的两个操作\n",
    "</p>\n",
    "\n",
    "- flatMap\n",
    "- reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_rdd = rdd_1.flatMap(lambda x: [x, x])\n",
    "new_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_2 = sc.parallelize([('a', 1), ('a', 2), ('b', 5), ('b', 5), ('b', 2)])\n",
    "new_rdd = rdd_2.reduceByKey(lambda result, x: result + x)\n",
    "new_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.5em;color:purple; font-style:bold\">\n",
    "练习 - Spark版单词计数\n",
    "</p>\n",
    "\n",
    "1. 打开I9000的jupyter terminal\n",
    "2. 运行pyspark\n",
    "3. 输入下面代码运行，一次一行\n",
    "\n",
    "** hdfs://XXX 替换为刚才上传文件在HDFS上的URI **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile('hdfs://XXX')\n",
    "f = lambda line: [(str(word).lower(), 1) for word in line.split()]\n",
    "words = lines.flatMap(f)\n",
    "word_count_rdd = words.reduceByKey(lambda total, count: total + count)\n",
    "word_count_rdd.take(3)\n",
    "word_to_count = dict(word_count_rdd.collect())\n",
    "word_to_count['spark']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
